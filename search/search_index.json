{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Open source, dynamic edge observability. \u00b6 Get Started with Orb Why Orb? \u00b6 Distributed deep network observability \u00b6 Orb manages a fleet of agents deployed across distributed, hybrid infrastructure: containers , VMs , servers , routers , and switches . Agents tap into traffic streams and extract real-time insights, resulting in lightweight, actionable metrics. The result: faster time-to-action at a lower cost. Streaming analysis at the edge \u00b6 Powered by the pktvisor observability agent , Orb's goal is to push analysis to the edge , where high-resolution data can be analysed in real time without the need to send raw data to a central location for batch processing. Current analysis focuses on L2-L3 Network, DNS, Flow, and DHCP with more analyzers in the works. Real-time agent orchestration \u00b6 Orb uses Internet of Things (IoT) principles to allow the observability agents to connect out from edge infrastructure to the Orb central control plane , avoiding firewall problems. Once connected, agents are controlled in real time from the Orb Portal or REST API, orchestrating observability policies designed to precisely extract the desired insights. Agents are grouped and addressed based on tags . Flexible integration with modern observability stacks \u00b6 Orb was built to integrate with modern observability stacks, supporting Prometheus natively and designed to support a host of sinks in the future, powered by OpenTelemetry . Collection and sinking of the metrics from the agents is included\u2014there is no need to run additional data collection pipelines for Orb metrics. Portal and REST API out of the box \u00b6 Orb includes a modern, responsive user interfacce for managing agents , agent groups , policies , datasets , and sinks . Orb is API-first, and all platform functionality is available for automation via the well-documented REST API . Open source, vendor neutral, cloud native \u00b6 Orb is free, open source software (FOSS) released under Mozilla Public License (MPL). It's a modern microservices application that can be deployed to any Kubernetes service in a private or public cloud. It does not depend on any single vendor to function, thus avoiding vendor lock-in. If you prefer not to run your own control plane, you can use the free https://orb.live community site instead, and get started immediately. Backed by NS1 \u00b6 Orb was born at NS1 Labs , where we're committed to making open source, dynamic edge observability a reality .","title":"Home"},{"location":"#open-source-dynamic-edge-observability","text":"Get Started with Orb","title":"Open source, dynamic edge observability."},{"location":"#why-orb","text":"","title":"Why Orb?"},{"location":"#distributed-deep-network-observability","text":"Orb manages a fleet of agents deployed across distributed, hybrid infrastructure: containers , VMs , servers , routers , and switches . Agents tap into traffic streams and extract real-time insights, resulting in lightweight, actionable metrics. The result: faster time-to-action at a lower cost.","title":"Distributed deep network observability"},{"location":"#streaming-analysis-at-the-edge","text":"Powered by the pktvisor observability agent , Orb's goal is to push analysis to the edge , where high-resolution data can be analysed in real time without the need to send raw data to a central location for batch processing. Current analysis focuses on L2-L3 Network, DNS, Flow, and DHCP with more analyzers in the works.","title":"Streaming analysis at the edge"},{"location":"#real-time-agent-orchestration","text":"Orb uses Internet of Things (IoT) principles to allow the observability agents to connect out from edge infrastructure to the Orb central control plane , avoiding firewall problems. Once connected, agents are controlled in real time from the Orb Portal or REST API, orchestrating observability policies designed to precisely extract the desired insights. Agents are grouped and addressed based on tags .","title":"Real-time agent orchestration"},{"location":"#flexible-integration-with-modern-observability-stacks","text":"Orb was built to integrate with modern observability stacks, supporting Prometheus natively and designed to support a host of sinks in the future, powered by OpenTelemetry . Collection and sinking of the metrics from the agents is included\u2014there is no need to run additional data collection pipelines for Orb metrics.","title":"Flexible integration with modern observability stacks"},{"location":"#portal-and-rest-api-out-of-the-box","text":"Orb includes a modern, responsive user interfacce for managing agents , agent groups , policies , datasets , and sinks . Orb is API-first, and all platform functionality is available for automation via the well-documented REST API .","title":"Portal and REST API out of the box"},{"location":"#open-source-vendor-neutral-cloud-native","text":"Orb is free, open source software (FOSS) released under Mozilla Public License (MPL). It's a modern microservices application that can be deployed to any Kubernetes service in a private or public cloud. It does not depend on any single vendor to function, thus avoiding vendor lock-in. If you prefer not to run your own control plane, you can use the free https://orb.live community site instead, and get started immediately.","title":"Open source, vendor neutral, cloud native"},{"location":"#backed-by-ns1","text":"Orb was born at NS1 Labs , where we're committed to making open source, dynamic edge observability a reality .","title":"Backed by NS1"},{"location":"about/","text":"The story \u00b6 Born at NS1 Labs , Orb is a new kind of observability platform that makes it easier for operators and developers to gain a deeper understanding of their networks, distributed applications, and traffic flows in real time. Orb integrates with your observability stack, providing dynamic orchestration of observability agents that extract business intelligence at the edge. The platform is completely open source , extensible, vendor neutral, and cloud native. The components \u00b6 The agents \u00b6 Orb manages observability agents that collect network data from applications, systems, and edge locations (VMs, containers, servers) in real time. An agent acts as a sensor installed next to a data source so it can collect, analyze, and summarize information. You run agents on your edge locations and orchestrate them via the control plane. While ingesting a high volume of information-dense data streams, the agents translate this information to deliver consumable, actionable datasets. Developers and network operators can view this data locally at the edge via the agent's command-line interface (CLI) and globally in a central database via a standard dashboard tool, such as Grafana. The control plane \u00b6 Orb combines concepts from edge computing, the Internet of Things (IoT), and high-throughput stream processing. As an IoT-inspired cloud control plane , Orb connects a fleet of distributed observability agents (such as the open source pktvisor ) deployed at the edge and gives you command over that fleet. In operating the control plane, you issue instructions to the agents, dynamically programming and re-programming them with data-collection policies to build different datasets in real time. The features \u00b6 Orb orchestrates network observability policies across a fleet of agents on the edge\u2014providing you with lightweight, immediately actionable results. Plugs into popular observability stacks, like Prometheus and Elasticsearch, as well as cloud storage and data pipelines Built using a cloud-native, microservices-based architecture Offers a self-hosted (via Docker Compose or Kubernetes) or a SaaS option Orb focuses on edge analysis, preferring \u201csmall data\u201d-style, actionable metrics over the collection and storage of terabytes of raw, inscrutable data. Allows you to visualize and automate on data at the edge for a hyper-real-time local view or centrally in the cloud for a global view Streamlines data collection and exporting back to the control plane where it is available for analytics, security, automation, etc. Provides a single pane of glass across all sensors Orb + pktvisor \u00b6 Via Orb's user interface , you decide what data to extract from which agents . The resource-efficient, side-car style pktvisor observability agent performs edge analysis on network data streams. This combination allows you to: Adjust analysis and collection parameters dynamically across the entire fleet via a powerful control plane Perform centralized fleet management, allowing you to configure heartbeats, tagging, and grouping for each of the pktvisor agents Orchestrate dataset policies that specify the type of data to extract from each agent In terms of metrics, pktvisor can capture DNS, DHCP, and L2/L3 network data via packet capture, dnstap , sflow , among other input methods. For a complete list of metrics currently collected by pktvisor, look here . To view a Grafana dashboard for visualizing pktvisor Prometheus metrics, look here . Core Concepts \u00b6 The concepts below comprise Orb\u2019s architecture. Agent \u00b6 This is a sensor installed next to a data source at the edge so it can summarize, analyze, and collect information. Agent group \u00b6 This is a list of simple key/value pairs that match against agent tags to dynamically define a group of agents. For example, \u201cregion: US\u201d will group all agents in the fleet that have this key/value set in their tags. Fleet \u00b6 This is a collection of agents that may be widely distributed and number in the tens, hundreds, or thousands\u2014all of which are able to connect and contribute to the same observability system. Policies \u00b6 These are instructions sent to the agents to define how to collect metrics . It is backend-specific information needed at the edge. Dataset \u00b6 These are instructions that describe how specific agents in the fleet (matched according to a given agent group) should apply collection policies and where they should sink their data . Orb will manage many datasets concurrently. Sinks \u00b6 This is where you send the data. This is the system that collects the data and allows you to sync it to different locations . Currently, Orb supports Prometheus but will support more backends in the future.","title":"About"},{"location":"about/#the-story","text":"Born at NS1 Labs , Orb is a new kind of observability platform that makes it easier for operators and developers to gain a deeper understanding of their networks, distributed applications, and traffic flows in real time. Orb integrates with your observability stack, providing dynamic orchestration of observability agents that extract business intelligence at the edge. The platform is completely open source , extensible, vendor neutral, and cloud native.","title":"The story"},{"location":"about/#the-components","text":"","title":"The components"},{"location":"about/#the-agents","text":"Orb manages observability agents that collect network data from applications, systems, and edge locations (VMs, containers, servers) in real time. An agent acts as a sensor installed next to a data source so it can collect, analyze, and summarize information. You run agents on your edge locations and orchestrate them via the control plane. While ingesting a high volume of information-dense data streams, the agents translate this information to deliver consumable, actionable datasets. Developers and network operators can view this data locally at the edge via the agent's command-line interface (CLI) and globally in a central database via a standard dashboard tool, such as Grafana.","title":"The agents"},{"location":"about/#the-control-plane","text":"Orb combines concepts from edge computing, the Internet of Things (IoT), and high-throughput stream processing. As an IoT-inspired cloud control plane , Orb connects a fleet of distributed observability agents (such as the open source pktvisor ) deployed at the edge and gives you command over that fleet. In operating the control plane, you issue instructions to the agents, dynamically programming and re-programming them with data-collection policies to build different datasets in real time.","title":"The control plane"},{"location":"about/#the-features","text":"Orb orchestrates network observability policies across a fleet of agents on the edge\u2014providing you with lightweight, immediately actionable results. Plugs into popular observability stacks, like Prometheus and Elasticsearch, as well as cloud storage and data pipelines Built using a cloud-native, microservices-based architecture Offers a self-hosted (via Docker Compose or Kubernetes) or a SaaS option Orb focuses on edge analysis, preferring \u201csmall data\u201d-style, actionable metrics over the collection and storage of terabytes of raw, inscrutable data. Allows you to visualize and automate on data at the edge for a hyper-real-time local view or centrally in the cloud for a global view Streamlines data collection and exporting back to the control plane where it is available for analytics, security, automation, etc. Provides a single pane of glass across all sensors","title":"The features"},{"location":"about/#orb-pktvisor","text":"Via Orb's user interface , you decide what data to extract from which agents . The resource-efficient, side-car style pktvisor observability agent performs edge analysis on network data streams. This combination allows you to: Adjust analysis and collection parameters dynamically across the entire fleet via a powerful control plane Perform centralized fleet management, allowing you to configure heartbeats, tagging, and grouping for each of the pktvisor agents Orchestrate dataset policies that specify the type of data to extract from each agent In terms of metrics, pktvisor can capture DNS, DHCP, and L2/L3 network data via packet capture, dnstap , sflow , among other input methods. For a complete list of metrics currently collected by pktvisor, look here . To view a Grafana dashboard for visualizing pktvisor Prometheus metrics, look here .","title":"Orb + pktvisor"},{"location":"about/#core-concepts","text":"The concepts below comprise Orb\u2019s architecture.","title":"Core Concepts"},{"location":"about/#agent","text":"This is a sensor installed next to a data source at the edge so it can summarize, analyze, and collect information.","title":"Agent"},{"location":"about/#agent-group","text":"This is a list of simple key/value pairs that match against agent tags to dynamically define a group of agents. For example, \u201cregion: US\u201d will group all agents in the fleet that have this key/value set in their tags.","title":"Agent group"},{"location":"about/#fleet","text":"This is a collection of agents that may be widely distributed and number in the tens, hundreds, or thousands\u2014all of which are able to connect and contribute to the same observability system.","title":"Fleet"},{"location":"about/#policies","text":"These are instructions sent to the agents to define how to collect metrics . It is backend-specific information needed at the edge.","title":"Policies"},{"location":"about/#dataset","text":"These are instructions that describe how specific agents in the fleet (matched according to a given agent group) should apply collection policies and where they should sink their data . Orb will manage many datasets concurrently.","title":"Dataset"},{"location":"about/#sinks","text":"This is where you send the data. This is the system that collects the data and allows you to sync it to different locations . Currently, Orb supports Prometheus but will support more backends in the future.","title":"Sinks"},{"location":"contact/","text":"Community \u00b6 Contribute \u00b6 Orb is an open source project born at NS1 Labs . Work with us on GitHub and star the project to show your interest. Star Contact \u00b6 We are very interested to hear about your use cases, feature requests, and contribution ideas. Sign up to get Orb updates File an issue Follow our public work board Start a discussion Join us on Slack Check out the NS1 Labs YouTube channel Send mail to info@pktvisor.dev Explore \u00b6 Articles \u00b6 Orb Data Sheet: Actionable Edge Observability Using DNS to Minimize Cyber Threat Exposure Deep Network Traffic Observability with Pktvisor and Prometheus Q4 2021 Update on NS1 Labs: pktvisor, Orb, NetBox Cloud Extracting the Signal: Rethinking Network Observability Orb - A New Paradigm for Dynamic Edge Observability A Wave of Open Source Innovation at NS1 Labs with Orb and NetBox NS1 Launches Innovation Lab to Solve Challenges in Modern Application Delivery and Edge Networking Conference Presentations \u00b6 NANOG 85 Montreal: On the Edge of Small Data , 2022 - Recording , Slides PromCon North America: Deep Network Traffic Observability , 2021 - Recording , Slides NS1 INSIGHTS 2021: Build the Better Future , 2021 - Recording ICANN DNS Symposium , 2021 - Recording , Slides DNS-OARC , 2020 - Recording (first talk), Slides O'Reilly Velocity San Jose , 2019 - Recording , Slides","title":"Community"},{"location":"contact/#community","text":"","title":"Community"},{"location":"contact/#contribute","text":"Orb is an open source project born at NS1 Labs . Work with us on GitHub and star the project to show your interest. Star","title":"Contribute"},{"location":"contact/#contact","text":"We are very interested to hear about your use cases, feature requests, and contribution ideas. Sign up to get Orb updates File an issue Follow our public work board Start a discussion Join us on Slack Check out the NS1 Labs YouTube channel Send mail to info@pktvisor.dev","title":"Contact"},{"location":"contact/#explore","text":"","title":"Explore"},{"location":"contact/#articles","text":"Orb Data Sheet: Actionable Edge Observability Using DNS to Minimize Cyber Threat Exposure Deep Network Traffic Observability with Pktvisor and Prometheus Q4 2021 Update on NS1 Labs: pktvisor, Orb, NetBox Cloud Extracting the Signal: Rethinking Network Observability Orb - A New Paradigm for Dynamic Edge Observability A Wave of Open Source Innovation at NS1 Labs with Orb and NetBox NS1 Launches Innovation Lab to Solve Challenges in Modern Application Delivery and Edge Networking","title":"Articles"},{"location":"contact/#conference-presentations","text":"NANOG 85 Montreal: On the Edge of Small Data , 2022 - Recording , Slides PromCon North America: Deep Network Traffic Observability , 2021 - Recording , Slides NS1 INSIGHTS 2021: Build the Better Future , 2021 - Recording ICANN DNS Symposium , 2021 - Recording , Slides DNS-OARC , 2020 - Recording (first talk), Slides O'Reilly Velocity San Jose , 2019 - Recording , Slides","title":"Conference Presentations"},{"location":"docs/","text":"Documentation \u00b6 Getting started \u00b6 Follow the steps below after logging in to your Orb Portal to get an agent up and running. Register a new account \u00b6 After registering, you should see the home page with a welcome message. Create an Agent \u00b6 You create an agent for each node you want to monitor. Agents are organized by tags. Each agent has a set of corresponding credentials used during provisioning. You may also provision agents directly at the edge instead of through the UI. Navigate to Agents , and then click New Agent . Fill in an Agent Name and click Next . Optionally, fill in Key and Value tags, then click the + on the right side of the menu. These tags represent the way you will assign the agent to an agent group. Reasonable tags might be \"location\", \"region\", \"pop\", \"type\", etc. You should see an icon with your key and value tags appear above the Key and Value textboxes. Click Next . Click Save to confirm your agent\u2019s name and tags. Your agent credentials should appear. Copy the Provisioning Command . This command contains all the information you need to run the Docker container with the given credentials you now have for the agent. Paste the Provisioning Command into your terminal (optionally edit \"mock\" to be real) and run the command. See Running Orb Agent for more details. Close out of the Agent Credentials menu. Refresh the Agents List in UI. The agent you just created should display an Online status. Optionally, click the agent's name to view the Agent View screen. This screen will contain more information as you add the agent to an agent group and add corresponding policies and datasets. Create an Agent Group \u00b6 Agents are organized into agent groups based on key-value tag matching. Navigate to Agent Groups , and then click New Agent Group . Fill in an Agent Group Name and click Next . Fill in the Key and Value tags, which need to match the tags of the corresponding Agent , and click the + on the right side of the menu. You should see an icon with your key and value tags appear above the Key and Value textboxes. Click Next . You should see a message about the number of agents matching. Then click Save . \ud83d\udca1 By clicking in EXPAND you can see the agents that are matching with the group (This is optional). View the newly created group in the Agent Groups list. Click the number in the Agents column to view the matching agents. Create a Sink \u00b6 A sink is a location to send the metrics collected from the agents. The current version supports Prometheus, and future versions will support more options. You can use a private Prometheus instance or use a free Grafana Cloud account as a sink. Navigate to Sink Management , and then click New Sink . Fill in a sink name and click Next . Fill in your sink destination details. This includes the host/username/password from your Prometheus remote_write configuration. Optionally, add sink tags by filling in the Key and Value fields. Click + after each key-value pair, and then click Next . Review and confirm your sink details and click Save . View your newly created sink in the All Sinks list. Create a Policy \u00b6 Policies tell agents which metrics to collect and how to collect them. Navigate to Policy Management , and then click New Policy . Fill in a policy name and (optionally) a description. The policy name needs to be unique and cannot contain spaces (use underscores or dashes instead). Then click Next . Select the Tap (input stream) to analyze. In this example, we use \u201cdefault_pcap\u201d which is the default for Packet Capture. All other options are advanced and can be left as is. Click Next . Click Add Handler to add a Stream Handler to the policy, which specifies how to analyze the input stream selected in the previous step. Add a Handler Label for each handler you add. In this example, we want to analyze DNS traffic, so we select the \u201cdns\u201d handler. The only required field here is the Handler Label , which is automatically generated for you (handler_dns_1 in this case). Enter any customization variables. In this example, we customize the analysis by analyzing only domain names ending in \".ua\" or \".ru\". This is done with the filter labeled \"Include Only QNames With Suffix.\" We input a comma delimited list of suffixes, so enter \".ua,.ru\". Click Save after entering any customization to save this Handler. You should see your new handler label on the screen. Optionally, add more handlers. Click Save to save the policy. Create a Dataset \u00b6 Datasets essentially connect all of the previous pieces. By creating and defining a dataset, you send a specific policy to a specific agent group and establish a sink to receive the resulting metrics which allows you to visualize and action on the data. Navigate to the Policy you would like to create a Dataset for, then click on New Dataset. Select the Agent Group to send the policy to, the Sink(s) you would like to send the resulting metrics to, and give the Dataset a name. As soon as you click Save , the policy will be sent in real time to the Agents in the Agent Group and begin running. Verify your dataset is active via the Agent View screen. Navigate to Agents and click on the name of the agent that matches the group you selected in creating the dataset. The Agent View screen displays. Under the Active Policies/Datasets category, click the Policy drop-down (which should accompany a \"running\" status), and your Dataset should display. Check Orb Health \u00b6 Orb objects have status variables whose functions are to help you understand the health of your system. Below is a guide to the correct interpretations of each status. Agent Status \u00b6 There are 4 expected status for agents: new , online , offline and stale These status are related to the agent's last activity (heartbeat): \ud83d\udfe3 new means that the agent never sent a heartbeat (i.e. has never connected to the control plane) \ud83d\udfe2 online means that the agent is sending heartbeats right now (is running and healthy). \u26aa offline means that the control plane received a heartbeat saying that the agent is going offline. \ud83d\udfe0 stale means that the control plane has not received a heartbeat for 5 minutes (without having received a heartbeat stating that it would go offline) Policies Status \u00b6 The status of each policy can be seen on the preview page of an agent to which it is applied The policy will be: running if agent policy is being managed from the control plane (policy-related metrics are being requested/scraped by this agent) failed_to_apply if an error prevents the policy from being applied by the agent. By clicking on the expand icon you can see the cause of the error offline if the policy was stopped by agent request Datasets Validity \u00b6 Once created a dataset can only be valid (\ud83d\udfe2) or invalid (\ud83d\udd34) The dataset will always be valid as long as the policy, the group AND the sink linked to it exist in Orb. If the policy, the group OR the sink is removed from Orb, the dataset will become invalid . Note, in the image above, that the invalid dataset does not contain the group listed, as it has been removed from the Orb. Sinks Status \u00b6 \ud83d\udfe0 Unknown - No metrics have ever been published to this sink \ud83d\udfe2 Active - Metrics are actively being published to this sink \u26aa Idle - The last metrics published to this sink were more than 5 minutes ago \ud83d\udd34 Error - The sink tried to publish the metrics but failed. Attention: In this case, check that the sink credentials are configured correctly. Visualize and alert on your metrics \u00b6 Your agent should now be running the policy you created. After one minute of collection time, the metrics will be sent to your Prometheus sink. You may use standard tools for visualizing and alerting on your Prometheus metrics. A popular option is Grafana . A pre-made dashboard for visualizing Orb/pktvisor metrics is available for import here . Running Orb Agent \u00b6 An Orb agent needs to run on all the infrastructure (computers, servers, switches, VMs, k8s, etc.) to be monitored. It is a small, lightweight Docker process with an embedded pktvisor agent which connects into the Orb control plane to receive policies and send its metric output. To run an agent, you will need: Docker, to run the agent image ( ns1labs/orb-agent:develop ) Agent Credentials , which are provided to you by the Orb UI or REST API after creating an agent The Orb Control Plane host address (e.g. localhost or orb.live ) The network interface to monitor (e.g. eth0 ) Tip If you are unsure which network interface to monitor, you may list the available interfaces on your host. Note that to allow the agent access to these interfaces, you must run the container with --net=host Linux ip -stats -color -human addr OSX ifconfig Agent credentials \u00b6 The agent credentials include three pieces of information , each of which is a UUID in the form 5dc34ded-6a53-44c0-8d15-7e9c8c95391a . Agent ID , which uniquely identifies the agent. Agent Channel ID , which uniquely identifies the agent's communication channel. Agent Key , which is a private access token for the agent. Note you will only be shown the key once upon creation! Sample provisioning commands \u00b6 Example Generic Use this command as a template by substituting in the appropriate values: docker run -d --net = host -e ORB_CLOUD_ADDRESS = <HOST> -e ORB_CLOUD_MQTT_ID = <AGENTID> -e ORB_CLOUD_MQTT_CHANNEL_ID = <CHANNELID> -e ORB_CLOUD_MQTT_KEY = <AGENTKEY> -e PKTVISOR_PCAP_IFACE_DEFAULT = mock ns1labs/orb-agent:develop localhost, mock This command is useful for connecting to a local develop environment, perhaps running on Docker compose . Note that the \"mock\" interface will generate random traffic rather than observe real traffic. docker run -d --net = host -e ORB_CLOUD_ADDRESS = localhost -e ORB_CLOUD_MQTT_ID = 7fb96f61-5de1-4f56-99d6-4eb8b43f8bad -e ORB_CLOUD_MQTT_CHANNEL_ID = 3e60e85d-4414-44d9-b564-0c1874898a4d -e ORB_CLOUD_MQTT_KEY = 44e42d90-aaef-45de-9bc2-2b2581eb30b3 -e PKTVISOR_PCAP_IFACE_DEFAULT = mock -e ORB_TLS_VERIFY = false ns1labs/orb-agent:develop orb.live, eth0 This command is similar to one you would use on the orb.live SaaS platform docker run -d --net = host -e ORB_CLOUD_ADDRESS = orb.live -e ORB_CLOUD_MQTT_ID = 7fb96f61-5de1-4f56-99d6-4eb8b43f8bad -e ORB_CLOUD_MQTT_CHANNEL_ID = 3e60e85d-4414-44d9-b564-0c1874898a4d -e ORB_CLOUD_MQTT_KEY = 44e42d90-aaef-45de-9bc2-2b2581eb30b3 -e PKTVISOR_PCAP_IFACE_DEFAULT = eth0 ns1labs/orb-agent:develop You may want to run more than one agent on the same node and for that you must specify different pktvisor control ports for them, since the containers run in host networking mode, only one is allowed to run per port. By default, the pktvisor control port runs on port 10853 , but this value can be set through the environment variable ORB_BACKENDS_PKTVISOR_API_PORT docker run -d --net = host -e ORB_CLOUD_ADDRESS = orb.live -e ORB_CLOUD_MQTT_ID = 7fb96f61-5de1-4f56-99d6-4eb8b43f8bad -e ORB_CLOUD_MQTT_CHANNEL_ID = 3e60e85d-4414-44d9-b564-0c1874898a4d -e ORB_CLOUD_MQTT_KEY = 44e42d90-aaef-45de-9bc2-2b2581eb30b3 -e PKTVISOR_PCAP_IFACE_DEFAULT = eth0 -e ORB_BACKENDS_PKTVISOR_API_PORT = 10854 ns1labs/orb-agent:develop \ud83c\udf81 BONUS - you can access agent debug logs by passing the -d command docker run -d --net = host -e ORB_CLOUD_ADDRESS = orb.live -e ORB_CLOUD_MQTT_ID = 7fb96f61-5de1-4f56-99d6-4eb8b43f8bad -e ORB_CLOUD_MQTT_CHANNEL_ID = 3e60e85d-4414-44d9-b564-0c1874898a4d -e ORB_CLOUD_MQTT_KEY = 44e42d90-aaef-45de-9bc2-2b2581eb30b3 -e PKTVISOR_PCAP_IFACE_DEFAULT = eth0 ns1labs/orb-agent:develop run -d Question Is the agent Docker image not starting correctly? Do you have a specific use case? Have you found a bug? Come talk to us live on Slack , or file a GitHub issue here . Configuration files \u00b6 Most configuration options can be passed to the container as environment variables, but there are some situations that require a configuration file. You will need to use a configuration file if: You want to assign tags to the agent at the edge You want to setup custom pktvisor Taps You want the agent to auto-provision The configuration file is written in YAML. You can use the latest template configuration file as a starting point, or start here: version : \"1.0\" # this section is used by pktvisor # see https://github.com/ns1labs/pktvisor/blob/develop/RFCs/2021-04-16-75-taps.md visor : taps : default_pcap : input_type : pcap config : iface : \"eth0\" host_spec : \"192.168.0.54/32,192.168.0.55/32,127.0.0.1/32\" # this section is used orb-agent # most sections and keys are optional orb : # these are arbitrary key value pairs used for organization in the control plane and UI tags : region : EU pop : ams02 node_type : dns cloud : config : # optionally specify an agent name to use during auto provisioning # hostname will be used if it's not specified here agent_name : my-agent1 auto_provision : true api : address : https://orb.live # if auto provisioning, specify API token here (or pass on the command line) token : TOKEN mqtt : address : tls://orb.live:8883 # if not auto provisioning, specify agent connection details here id : \"AGENT_UUID\" key : \"AGENT_KEY_UUID\" channel_id : \"AGENT_CHANNEL_UUID\" backends : pktvisor : binary : \"/usr/local/sbin/pktvisord\" # this example assumes the file is saved as agent.yaml. If your file has another name, you must replace it with the proper name config_file : \"/usr/local/orb/etc/agent.yaml\" You must mount your configuration file into the orb-agent container. For example, if your configuration file is on the host at /local/orb/agent.yaml , you can mount it into the container with this command: docker run -v /local/orb:/usr/local/orb/ --net = host \\ ns1labs/orb-agent:develop run -c /usr/local/orb/agent.yaml Advanced auto-provisioning setup \u00b6 Some use cases require a way to provision agents directly on edge infrastructure without creating an agent manually in the UI or REST API ahead of time. To do so, you will need to create an API key which can be used by orb-agent to provision itself. Warning Auto-provisioning is an advanced use case. Most users will find creating an agent in the UI easier. If you have not already done so, register a new account with an email address and password at https://HOST/auth/register. Create a SESSION_TOKEN with the EMAIL_ADDRESS and PASSWORD from registration: curl --location --request POST 'https://HOST/api/v1/tokens' \\ --header 'Content-Type: application/json' \\ --data-raw '{ \"email\": \"<EMAIL_ADDRESS>\", \"password\": \"<PASSWORD>\" }' The output from creating a session token looks like this: { \"token\": \"SESSION_TOKEN\" } Because session tokens expire after 24 hours, you can create a permanent API token for agent provisioning by using the SESSION_TOKEN above: curl --location --request POST 'https://HOST/api/v1/keys' \\ --header 'Authorization: <SESSION_TOKEN>' \\ --header 'Content-Type: application/json' \\ --data-raw '{ \"type\": 2 }' The output from creating a PERMANENT_TOKEN looks like the following. Please take note of the id (used later to revoke) and the value (the permanent API token): { \"id\": \"710c6a92-b463-42ec-bf24-8ae24eb13081\", \"value\": \"PERMANENT_TOKEN\", \"issued_at\": \"2021-09-07T15:29:49.70146088Z\" } Currently, the permanent token allows access to all API functionality, not just provisioning. You can revoke this permanent token at any time with the following call, using the id field above: curl --location --request DELETE 'HOST:80/api/v1/keys/<PERMANENT_TOKEN_ID>' \\ --header 'Authorization: <SESSION_TOKEN>' Create a config for Orb and pktvisor taps, for example, /local/orb/agent.yaml : version : \"1.0\" visor : taps : ethernet : input_type : pcap config : iface : \"eth0\" orb : db : file : /usr/local/orb/orb-agent.db tags : region : EU pop : ams02 node_type : dns cloud : config : agent_name : myagent1 api : address : https://HOST mqtt : address : tls://HOST:8883 You can now pull and run ns1labs/orb-agent:develop to auto-provision, substituting in the PERMANENT_TOKEN and optionally configuring agent name and Orb tags. If you don't set the agent name, it will attempt to use a hostname. You must mount the directory to save the agent state database and the config file: docker pull ns1labs/orb-agent:develop docker run -v /local/orb:/usr/local/orb/ --net = host \\ -e ORB_CLOUD_API_TOKEN = <PERMANENT_TOKEN> \\ ns1labs/orb-agent:develop run -c /usr/local/orb/agent.yaml Working with API Docs \u00b6 Follow the links below for API documentation of each respective Orb microservice: Fleet Policies Sinks","title":"Documentation"},{"location":"docs/#documentation","text":"","title":"Documentation"},{"location":"docs/#getting-started","text":"Follow the steps below after logging in to your Orb Portal to get an agent up and running.","title":"Getting started"},{"location":"docs/#register-a-new-account","text":"After registering, you should see the home page with a welcome message.","title":"Register a new account"},{"location":"docs/#create-an-agent","text":"You create an agent for each node you want to monitor. Agents are organized by tags. Each agent has a set of corresponding credentials used during provisioning. You may also provision agents directly at the edge instead of through the UI. Navigate to Agents , and then click New Agent . Fill in an Agent Name and click Next . Optionally, fill in Key and Value tags, then click the + on the right side of the menu. These tags represent the way you will assign the agent to an agent group. Reasonable tags might be \"location\", \"region\", \"pop\", \"type\", etc. You should see an icon with your key and value tags appear above the Key and Value textboxes. Click Next . Click Save to confirm your agent\u2019s name and tags. Your agent credentials should appear. Copy the Provisioning Command . This command contains all the information you need to run the Docker container with the given credentials you now have for the agent. Paste the Provisioning Command into your terminal (optionally edit \"mock\" to be real) and run the command. See Running Orb Agent for more details. Close out of the Agent Credentials menu. Refresh the Agents List in UI. The agent you just created should display an Online status. Optionally, click the agent's name to view the Agent View screen. This screen will contain more information as you add the agent to an agent group and add corresponding policies and datasets.","title":"Create an Agent"},{"location":"docs/#create-an-agent-group","text":"Agents are organized into agent groups based on key-value tag matching. Navigate to Agent Groups , and then click New Agent Group . Fill in an Agent Group Name and click Next . Fill in the Key and Value tags, which need to match the tags of the corresponding Agent , and click the + on the right side of the menu. You should see an icon with your key and value tags appear above the Key and Value textboxes. Click Next . You should see a message about the number of agents matching. Then click Save . \ud83d\udca1 By clicking in EXPAND you can see the agents that are matching with the group (This is optional). View the newly created group in the Agent Groups list. Click the number in the Agents column to view the matching agents.","title":"Create an Agent Group"},{"location":"docs/#create-a-sink","text":"A sink is a location to send the metrics collected from the agents. The current version supports Prometheus, and future versions will support more options. You can use a private Prometheus instance or use a free Grafana Cloud account as a sink. Navigate to Sink Management , and then click New Sink . Fill in a sink name and click Next . Fill in your sink destination details. This includes the host/username/password from your Prometheus remote_write configuration. Optionally, add sink tags by filling in the Key and Value fields. Click + after each key-value pair, and then click Next . Review and confirm your sink details and click Save . View your newly created sink in the All Sinks list.","title":"Create a Sink"},{"location":"docs/#create-a-policy","text":"Policies tell agents which metrics to collect and how to collect them. Navigate to Policy Management , and then click New Policy . Fill in a policy name and (optionally) a description. The policy name needs to be unique and cannot contain spaces (use underscores or dashes instead). Then click Next . Select the Tap (input stream) to analyze. In this example, we use \u201cdefault_pcap\u201d which is the default for Packet Capture. All other options are advanced and can be left as is. Click Next . Click Add Handler to add a Stream Handler to the policy, which specifies how to analyze the input stream selected in the previous step. Add a Handler Label for each handler you add. In this example, we want to analyze DNS traffic, so we select the \u201cdns\u201d handler. The only required field here is the Handler Label , which is automatically generated for you (handler_dns_1 in this case). Enter any customization variables. In this example, we customize the analysis by analyzing only domain names ending in \".ua\" or \".ru\". This is done with the filter labeled \"Include Only QNames With Suffix.\" We input a comma delimited list of suffixes, so enter \".ua,.ru\". Click Save after entering any customization to save this Handler. You should see your new handler label on the screen. Optionally, add more handlers. Click Save to save the policy.","title":"Create a Policy"},{"location":"docs/#create-a-dataset","text":"Datasets essentially connect all of the previous pieces. By creating and defining a dataset, you send a specific policy to a specific agent group and establish a sink to receive the resulting metrics which allows you to visualize and action on the data. Navigate to the Policy you would like to create a Dataset for, then click on New Dataset. Select the Agent Group to send the policy to, the Sink(s) you would like to send the resulting metrics to, and give the Dataset a name. As soon as you click Save , the policy will be sent in real time to the Agents in the Agent Group and begin running. Verify your dataset is active via the Agent View screen. Navigate to Agents and click on the name of the agent that matches the group you selected in creating the dataset. The Agent View screen displays. Under the Active Policies/Datasets category, click the Policy drop-down (which should accompany a \"running\" status), and your Dataset should display.","title":"Create a Dataset"},{"location":"docs/#check-orb-health","text":"Orb objects have status variables whose functions are to help you understand the health of your system. Below is a guide to the correct interpretations of each status.","title":"Check Orb Health"},{"location":"docs/#agent-status","text":"There are 4 expected status for agents: new , online , offline and stale These status are related to the agent's last activity (heartbeat): \ud83d\udfe3 new means that the agent never sent a heartbeat (i.e. has never connected to the control plane) \ud83d\udfe2 online means that the agent is sending heartbeats right now (is running and healthy). \u26aa offline means that the control plane received a heartbeat saying that the agent is going offline. \ud83d\udfe0 stale means that the control plane has not received a heartbeat for 5 minutes (without having received a heartbeat stating that it would go offline)","title":"Agent Status"},{"location":"docs/#policies-status","text":"The status of each policy can be seen on the preview page of an agent to which it is applied The policy will be: running if agent policy is being managed from the control plane (policy-related metrics are being requested/scraped by this agent) failed_to_apply if an error prevents the policy from being applied by the agent. By clicking on the expand icon you can see the cause of the error offline if the policy was stopped by agent request","title":"Policies Status"},{"location":"docs/#datasets-validity","text":"Once created a dataset can only be valid (\ud83d\udfe2) or invalid (\ud83d\udd34) The dataset will always be valid as long as the policy, the group AND the sink linked to it exist in Orb. If the policy, the group OR the sink is removed from Orb, the dataset will become invalid . Note, in the image above, that the invalid dataset does not contain the group listed, as it has been removed from the Orb.","title":"Datasets Validity"},{"location":"docs/#sinks-status","text":"\ud83d\udfe0 Unknown - No metrics have ever been published to this sink \ud83d\udfe2 Active - Metrics are actively being published to this sink \u26aa Idle - The last metrics published to this sink were more than 5 minutes ago \ud83d\udd34 Error - The sink tried to publish the metrics but failed. Attention: In this case, check that the sink credentials are configured correctly.","title":"Sinks Status"},{"location":"docs/#visualize-and-alert-on-your-metrics","text":"Your agent should now be running the policy you created. After one minute of collection time, the metrics will be sent to your Prometheus sink. You may use standard tools for visualizing and alerting on your Prometheus metrics. A popular option is Grafana . A pre-made dashboard for visualizing Orb/pktvisor metrics is available for import here .","title":"Visualize and alert on your metrics"},{"location":"docs/#running-orb-agent","text":"An Orb agent needs to run on all the infrastructure (computers, servers, switches, VMs, k8s, etc.) to be monitored. It is a small, lightweight Docker process with an embedded pktvisor agent which connects into the Orb control plane to receive policies and send its metric output. To run an agent, you will need: Docker, to run the agent image ( ns1labs/orb-agent:develop ) Agent Credentials , which are provided to you by the Orb UI or REST API after creating an agent The Orb Control Plane host address (e.g. localhost or orb.live ) The network interface to monitor (e.g. eth0 ) Tip If you are unsure which network interface to monitor, you may list the available interfaces on your host. Note that to allow the agent access to these interfaces, you must run the container with --net=host Linux ip -stats -color -human addr OSX ifconfig","title":"Running Orb Agent"},{"location":"docs/#agent-credentials","text":"The agent credentials include three pieces of information , each of which is a UUID in the form 5dc34ded-6a53-44c0-8d15-7e9c8c95391a . Agent ID , which uniquely identifies the agent. Agent Channel ID , which uniquely identifies the agent's communication channel. Agent Key , which is a private access token for the agent. Note you will only be shown the key once upon creation!","title":"Agent credentials"},{"location":"docs/#sample-provisioning-commands","text":"Example Generic Use this command as a template by substituting in the appropriate values: docker run -d --net = host -e ORB_CLOUD_ADDRESS = <HOST> -e ORB_CLOUD_MQTT_ID = <AGENTID> -e ORB_CLOUD_MQTT_CHANNEL_ID = <CHANNELID> -e ORB_CLOUD_MQTT_KEY = <AGENTKEY> -e PKTVISOR_PCAP_IFACE_DEFAULT = mock ns1labs/orb-agent:develop localhost, mock This command is useful for connecting to a local develop environment, perhaps running on Docker compose . Note that the \"mock\" interface will generate random traffic rather than observe real traffic. docker run -d --net = host -e ORB_CLOUD_ADDRESS = localhost -e ORB_CLOUD_MQTT_ID = 7fb96f61-5de1-4f56-99d6-4eb8b43f8bad -e ORB_CLOUD_MQTT_CHANNEL_ID = 3e60e85d-4414-44d9-b564-0c1874898a4d -e ORB_CLOUD_MQTT_KEY = 44e42d90-aaef-45de-9bc2-2b2581eb30b3 -e PKTVISOR_PCAP_IFACE_DEFAULT = mock -e ORB_TLS_VERIFY = false ns1labs/orb-agent:develop orb.live, eth0 This command is similar to one you would use on the orb.live SaaS platform docker run -d --net = host -e ORB_CLOUD_ADDRESS = orb.live -e ORB_CLOUD_MQTT_ID = 7fb96f61-5de1-4f56-99d6-4eb8b43f8bad -e ORB_CLOUD_MQTT_CHANNEL_ID = 3e60e85d-4414-44d9-b564-0c1874898a4d -e ORB_CLOUD_MQTT_KEY = 44e42d90-aaef-45de-9bc2-2b2581eb30b3 -e PKTVISOR_PCAP_IFACE_DEFAULT = eth0 ns1labs/orb-agent:develop You may want to run more than one agent on the same node and for that you must specify different pktvisor control ports for them, since the containers run in host networking mode, only one is allowed to run per port. By default, the pktvisor control port runs on port 10853 , but this value can be set through the environment variable ORB_BACKENDS_PKTVISOR_API_PORT docker run -d --net = host -e ORB_CLOUD_ADDRESS = orb.live -e ORB_CLOUD_MQTT_ID = 7fb96f61-5de1-4f56-99d6-4eb8b43f8bad -e ORB_CLOUD_MQTT_CHANNEL_ID = 3e60e85d-4414-44d9-b564-0c1874898a4d -e ORB_CLOUD_MQTT_KEY = 44e42d90-aaef-45de-9bc2-2b2581eb30b3 -e PKTVISOR_PCAP_IFACE_DEFAULT = eth0 -e ORB_BACKENDS_PKTVISOR_API_PORT = 10854 ns1labs/orb-agent:develop \ud83c\udf81 BONUS - you can access agent debug logs by passing the -d command docker run -d --net = host -e ORB_CLOUD_ADDRESS = orb.live -e ORB_CLOUD_MQTT_ID = 7fb96f61-5de1-4f56-99d6-4eb8b43f8bad -e ORB_CLOUD_MQTT_CHANNEL_ID = 3e60e85d-4414-44d9-b564-0c1874898a4d -e ORB_CLOUD_MQTT_KEY = 44e42d90-aaef-45de-9bc2-2b2581eb30b3 -e PKTVISOR_PCAP_IFACE_DEFAULT = eth0 ns1labs/orb-agent:develop run -d Question Is the agent Docker image not starting correctly? Do you have a specific use case? Have you found a bug? Come talk to us live on Slack , or file a GitHub issue here .","title":"Sample provisioning commands"},{"location":"docs/#configuration-files","text":"Most configuration options can be passed to the container as environment variables, but there are some situations that require a configuration file. You will need to use a configuration file if: You want to assign tags to the agent at the edge You want to setup custom pktvisor Taps You want the agent to auto-provision The configuration file is written in YAML. You can use the latest template configuration file as a starting point, or start here: version : \"1.0\" # this section is used by pktvisor # see https://github.com/ns1labs/pktvisor/blob/develop/RFCs/2021-04-16-75-taps.md visor : taps : default_pcap : input_type : pcap config : iface : \"eth0\" host_spec : \"192.168.0.54/32,192.168.0.55/32,127.0.0.1/32\" # this section is used orb-agent # most sections and keys are optional orb : # these are arbitrary key value pairs used for organization in the control plane and UI tags : region : EU pop : ams02 node_type : dns cloud : config : # optionally specify an agent name to use during auto provisioning # hostname will be used if it's not specified here agent_name : my-agent1 auto_provision : true api : address : https://orb.live # if auto provisioning, specify API token here (or pass on the command line) token : TOKEN mqtt : address : tls://orb.live:8883 # if not auto provisioning, specify agent connection details here id : \"AGENT_UUID\" key : \"AGENT_KEY_UUID\" channel_id : \"AGENT_CHANNEL_UUID\" backends : pktvisor : binary : \"/usr/local/sbin/pktvisord\" # this example assumes the file is saved as agent.yaml. If your file has another name, you must replace it with the proper name config_file : \"/usr/local/orb/etc/agent.yaml\" You must mount your configuration file into the orb-agent container. For example, if your configuration file is on the host at /local/orb/agent.yaml , you can mount it into the container with this command: docker run -v /local/orb:/usr/local/orb/ --net = host \\ ns1labs/orb-agent:develop run -c /usr/local/orb/agent.yaml","title":"Configuration files"},{"location":"docs/#advanced-auto-provisioning-setup","text":"Some use cases require a way to provision agents directly on edge infrastructure without creating an agent manually in the UI or REST API ahead of time. To do so, you will need to create an API key which can be used by orb-agent to provision itself. Warning Auto-provisioning is an advanced use case. Most users will find creating an agent in the UI easier. If you have not already done so, register a new account with an email address and password at https://HOST/auth/register. Create a SESSION_TOKEN with the EMAIL_ADDRESS and PASSWORD from registration: curl --location --request POST 'https://HOST/api/v1/tokens' \\ --header 'Content-Type: application/json' \\ --data-raw '{ \"email\": \"<EMAIL_ADDRESS>\", \"password\": \"<PASSWORD>\" }' The output from creating a session token looks like this: { \"token\": \"SESSION_TOKEN\" } Because session tokens expire after 24 hours, you can create a permanent API token for agent provisioning by using the SESSION_TOKEN above: curl --location --request POST 'https://HOST/api/v1/keys' \\ --header 'Authorization: <SESSION_TOKEN>' \\ --header 'Content-Type: application/json' \\ --data-raw '{ \"type\": 2 }' The output from creating a PERMANENT_TOKEN looks like the following. Please take note of the id (used later to revoke) and the value (the permanent API token): { \"id\": \"710c6a92-b463-42ec-bf24-8ae24eb13081\", \"value\": \"PERMANENT_TOKEN\", \"issued_at\": \"2021-09-07T15:29:49.70146088Z\" } Currently, the permanent token allows access to all API functionality, not just provisioning. You can revoke this permanent token at any time with the following call, using the id field above: curl --location --request DELETE 'HOST:80/api/v1/keys/<PERMANENT_TOKEN_ID>' \\ --header 'Authorization: <SESSION_TOKEN>' Create a config for Orb and pktvisor taps, for example, /local/orb/agent.yaml : version : \"1.0\" visor : taps : ethernet : input_type : pcap config : iface : \"eth0\" orb : db : file : /usr/local/orb/orb-agent.db tags : region : EU pop : ams02 node_type : dns cloud : config : agent_name : myagent1 api : address : https://HOST mqtt : address : tls://HOST:8883 You can now pull and run ns1labs/orb-agent:develop to auto-provision, substituting in the PERMANENT_TOKEN and optionally configuring agent name and Orb tags. If you don't set the agent name, it will attempt to use a hostname. You must mount the directory to save the agent state database and the config file: docker pull ns1labs/orb-agent:develop docker run -v /local/orb:/usr/local/orb/ --net = host \\ -e ORB_CLOUD_API_TOKEN = <PERMANENT_TOKEN> \\ ns1labs/orb-agent:develop run -c /usr/local/orb/agent.yaml","title":"Advanced auto-provisioning setup"},{"location":"docs/#working-with-api-docs","text":"Follow the links below for API documentation of each respective Orb microservice: Fleet Policies Sinks","title":"Working with API Docs"},{"location":"install/","text":"Orb consists of two major components: The Control Plane \u2014comprised of microservices, communication systems, databases, etc.\u2014deploys to a central location (usually a cloud environment on Kubernetes). The Orb Agent \u2014a lightweight observability agent\u2014deploys to all the infrastructure you wish to monitor. Info The instructions below are for installing the Control Plane . If you just need to install the Orb Agent ( orb-agent ), see these instructions instead . The Control Plane can be self-hosted , or you can use our free Orb SaaS service. Self-hosting gives you full privacy and control but is more complex. On the other hand, our SaaS gets you up and running quickly since you only need to create a free account on orb.live and then install the Orb Agent to your infrastructure. orb.live \u00b6 The Orb SaaS platform ( orb.live ) is now in active development. This free-forever service allows you to enjoy the benefits of the Orb platform without having to run your own control plane. If you need to install the Orb Agent to be used with orb.live, see these instructions . Self-host \u00b6 There are two main deployment methods for those wanting to self-host: Docker Compose - This option is useful for developer or testing installations, allowing you to run both the Orb Control Plane and the Orb Agent on a single machine. Helm Chart - This option is intended for production deployments, requiring access to a Kubernetes cluster. Follow the instructions below after choosing a self-host option. Tip If you're just interested in trying out Orb quickly to see what it's all about, use the Docker Compose method. Orb with Docker Compose \u00b6 The Orb repo contains a full Docker Compose environment, useful both for developers wishing to contribute and casual users looking to try Orb for the first time. Running Orb with Docker Compose requires you to have a copy of the Orb repo, although it is not necessary to build any software as the Compose file will download appropriate versions of the services from Docker Hub. If you would like to build the software, or if you need to troubleshoot your environment, you can find more detailed instructions on setting up a development environment here . Requirements \u00b6 git make Docker Docker Compose (minimum version 1.29.2) Instructions \u00b6 git clone https://github.com/ns1labs/orb.git cd orb make run This will pull Orb\u2019s containers from Docker Hub and start all services. You may run docker ps to confirm all services started successfully. If you are running on your local machine, upon success the Orb UI will be available at https://localhost/ Bug Is the Docker Compose environment not starting correctly? Found a bug? Come talk to us live on Slack , or file a GitHub issue here . Orb Helm Chart \u00b6 Helm is a package manager for Kubernetes. A Helm Chart is a package that allows you to customize your deployment on Kubernetes. To configure and deploy an Orb Helm Chart, follow the instructions below. Requirements \u00b6 Helm v3 Configuration \u00b6 This guide assumes installation into namespace orb . It requires a HOSTNAME over which you have DNS control. It uses Let's Encrypt for TLS certification management. cd to working directory charts/orb Add helm repos for dependencies. helm repo add jaegertracing https://jaegertracing.github.io/helm-charts helm repo add bitnami https://charts.bitnami.com/bitnami helm repo add ingress-nginx https://kubernetes.github.io/ingress-nginx helm repo add jetstack https://charts.jetstack.io helm repo update helm dependency update Create orb namespace. kubectl create namespace orb Create JWT signing key secret. kubectl create secret generic orb-auth-service --from-literal=jwtSecret=MY_SECRET -n orb Create admin user secrets. kubectl create secret generic orb-user-service --from-literal=adminEmail=user@example.com --from-literal=adminPassword=12345678 -n orb Deploy ingres-nginx helm (to default namespace) with tcp config map configured from helm for 8883 (MQTTS). Note you need to reference both namespace and helm release name here. helm install --set tcp.8883=orb/my-orb-nginx-internal:8883 ingress-nginx ingress-nginx/ingress-nginx Wait for an external IP to be available. kubectl --namespace default get services -o wide -w ingress-nginx-controller Choose a HOSTNAME, then point an A record for this hostname to the external IP. Deploy cert manager helm to secure nginx ingress . helm install cert-manager jetstack/cert-manager --namespace cert-manager --create-namespace --version v1.5.3 --set installCRDs=true Create Issuer CRDs (in the orb namespace). cp issuers/production-issuer-tpt.yaml issuers/production-issuer.yaml Edit issuers/production-issuer.yaml and change spec.acme.email to a real email address. kubectl create -f issuers/production-issuer.yaml -n orb Install Orb. Replace my-orb with your helm release name. helm install --set ingress.hostname=HOSTNAME -n orb my-orb . Bug Is the Helm deployment not working correctly? Found a bug? Come talk to us live on Slack , or file a GitHub issue here . Upon successful installation, visit our Getting Started section to keep moving forward with Orb. Orb with Kind \u00b6 Kind is a tool for running local k8s clusters using docker container as nodes. Follow those steps to setup a local k8s cluster and deploy Orb. Requirements \u00b6 Docker Environment Helm 3 Kubectl Kind Bug Windows WSL users : WSL is also supported, but for some reason the Orb stack mess up the WSL internal DNS. You can fix that by editing your /etc/wsl.conf and adding the following: [ network ] generateResolvConf = false Restart WSL by executing the following on CMD: wsl --shutdown Open WSL terminal again and remove the symbolic link from /etc/resolv.conf : sudo unlink /etc/resolv.conf Create a new /etc/resolv.conf file and add the following: nameserver 8 .8.8.8 save the file and you are done. Deploy Orb on Kind \u00b6 Add kubernetes.docker.internal host as 127.0.0.1 address in your hosts file: echo \"127.0.0.1 kubernetes.docker.internal\" | sudo tee -a /etc/hosts Clone the Orb Helm charts git clone git@github.com:ns1labs/orb-helm.git cd orb-helm Setup Orb Charts dependencies repositories: make prepare-helm Tip You just need to run those steps until here once, even if you delete the cluster afterwards. Use the following command to create the cluster and deploy Orb : make kind-create-all Access the Orb UI by accessing: https://kubernetes.docker.internal/. The following users are created during the mainflux bootstrap: E-mail Password Role admin@kind.com pass123456 Admin Have fun! \ud83c\udf89 When you are done, you can delete the cluster by running: make kind-delete-cluster","title":"Installation"},{"location":"install/#orblive","text":"The Orb SaaS platform ( orb.live ) is now in active development. This free-forever service allows you to enjoy the benefits of the Orb platform without having to run your own control plane. If you need to install the Orb Agent to be used with orb.live, see these instructions .","title":"orb.live"},{"location":"install/#self-host","text":"There are two main deployment methods for those wanting to self-host: Docker Compose - This option is useful for developer or testing installations, allowing you to run both the Orb Control Plane and the Orb Agent on a single machine. Helm Chart - This option is intended for production deployments, requiring access to a Kubernetes cluster. Follow the instructions below after choosing a self-host option. Tip If you're just interested in trying out Orb quickly to see what it's all about, use the Docker Compose method.","title":"Self-host"},{"location":"install/#orb-with-docker-compose","text":"The Orb repo contains a full Docker Compose environment, useful both for developers wishing to contribute and casual users looking to try Orb for the first time. Running Orb with Docker Compose requires you to have a copy of the Orb repo, although it is not necessary to build any software as the Compose file will download appropriate versions of the services from Docker Hub. If you would like to build the software, or if you need to troubleshoot your environment, you can find more detailed instructions on setting up a development environment here .","title":"Orb with Docker Compose"},{"location":"install/#requirements","text":"git make Docker Docker Compose (minimum version 1.29.2)","title":"Requirements"},{"location":"install/#instructions","text":"git clone https://github.com/ns1labs/orb.git cd orb make run This will pull Orb\u2019s containers from Docker Hub and start all services. You may run docker ps to confirm all services started successfully. If you are running on your local machine, upon success the Orb UI will be available at https://localhost/ Bug Is the Docker Compose environment not starting correctly? Found a bug? Come talk to us live on Slack , or file a GitHub issue here .","title":"Instructions"},{"location":"install/#orb-helm-chart","text":"Helm is a package manager for Kubernetes. A Helm Chart is a package that allows you to customize your deployment on Kubernetes. To configure and deploy an Orb Helm Chart, follow the instructions below.","title":"Orb Helm Chart"},{"location":"install/#requirements_1","text":"Helm v3","title":"Requirements"},{"location":"install/#configuration","text":"This guide assumes installation into namespace orb . It requires a HOSTNAME over which you have DNS control. It uses Let's Encrypt for TLS certification management. cd to working directory charts/orb Add helm repos for dependencies. helm repo add jaegertracing https://jaegertracing.github.io/helm-charts helm repo add bitnami https://charts.bitnami.com/bitnami helm repo add ingress-nginx https://kubernetes.github.io/ingress-nginx helm repo add jetstack https://charts.jetstack.io helm repo update helm dependency update Create orb namespace. kubectl create namespace orb Create JWT signing key secret. kubectl create secret generic orb-auth-service --from-literal=jwtSecret=MY_SECRET -n orb Create admin user secrets. kubectl create secret generic orb-user-service --from-literal=adminEmail=user@example.com --from-literal=adminPassword=12345678 -n orb Deploy ingres-nginx helm (to default namespace) with tcp config map configured from helm for 8883 (MQTTS). Note you need to reference both namespace and helm release name here. helm install --set tcp.8883=orb/my-orb-nginx-internal:8883 ingress-nginx ingress-nginx/ingress-nginx Wait for an external IP to be available. kubectl --namespace default get services -o wide -w ingress-nginx-controller Choose a HOSTNAME, then point an A record for this hostname to the external IP. Deploy cert manager helm to secure nginx ingress . helm install cert-manager jetstack/cert-manager --namespace cert-manager --create-namespace --version v1.5.3 --set installCRDs=true Create Issuer CRDs (in the orb namespace). cp issuers/production-issuer-tpt.yaml issuers/production-issuer.yaml Edit issuers/production-issuer.yaml and change spec.acme.email to a real email address. kubectl create -f issuers/production-issuer.yaml -n orb Install Orb. Replace my-orb with your helm release name. helm install --set ingress.hostname=HOSTNAME -n orb my-orb . Bug Is the Helm deployment not working correctly? Found a bug? Come talk to us live on Slack , or file a GitHub issue here . Upon successful installation, visit our Getting Started section to keep moving forward with Orb.","title":"Configuration"},{"location":"install/#orb-with-kind","text":"Kind is a tool for running local k8s clusters using docker container as nodes. Follow those steps to setup a local k8s cluster and deploy Orb.","title":"Orb with Kind"},{"location":"install/#requirements_2","text":"Docker Environment Helm 3 Kubectl Kind Bug Windows WSL users : WSL is also supported, but for some reason the Orb stack mess up the WSL internal DNS. You can fix that by editing your /etc/wsl.conf and adding the following: [ network ] generateResolvConf = false Restart WSL by executing the following on CMD: wsl --shutdown Open WSL terminal again and remove the symbolic link from /etc/resolv.conf : sudo unlink /etc/resolv.conf Create a new /etc/resolv.conf file and add the following: nameserver 8 .8.8.8 save the file and you are done.","title":"Requirements"},{"location":"install/#deploy-orb-on-kind","text":"Add kubernetes.docker.internal host as 127.0.0.1 address in your hosts file: echo \"127.0.0.1 kubernetes.docker.internal\" | sudo tee -a /etc/hosts Clone the Orb Helm charts git clone git@github.com:ns1labs/orb-helm.git cd orb-helm Setup Orb Charts dependencies repositories: make prepare-helm Tip You just need to run those steps until here once, even if you delete the cluster afterwards. Use the following command to create the cluster and deploy Orb : make kind-create-all Access the Orb UI by accessing: https://kubernetes.docker.internal/. The following users are created during the mainflux bootstrap: E-mail Password Role admin@kind.com pass123456 Admin Have fun! \ud83c\udf89 When you are done, you can delete the cluster by running: make kind-delete-cluster","title":"Deploy Orb on Kind"},{"location":"saas/","text":"The Orb software-as-a-service platform ( orb.live ) is now in development. Check back soon for the official release of the SaaS platform. Until then, interact with us today and check out pktvisor , a production-ready observability agent.","title":"Saas"}]}